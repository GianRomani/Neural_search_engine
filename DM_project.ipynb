{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GianRomani/Neural_search_engine/blob/main/DM_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not working on Colab, it should work in local. It is needed to use GPU with multiprocess (in Flow)\n",
        "%env JINA_MP_START_METHOD='spawn'\n",
        "import os\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "print(os.getenv(\"JINA_MP_START_METHOD\"))\n",
        "mp.set_start_method('spawn', force=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Psi4XQJzqmoC",
        "outputId": "9fb1ae27-dc0d-4db3-d34e-706cb253cda4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: JINA_MP_START_METHOD='spawn'\n",
            "'spawn'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btPirC-5-5B7",
        "outputId": "8f938753-a1a7-4cc9-a2ac-a4a205f6c432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "try: \n",
        "  #this will raise an error if you are not using Colab\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "except:\n",
        "  print(\"You are not using Colab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p-1HyapB_rPx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = pd.read_csv(\"/content/drive/MyDrive/DM/Questions.csv\", encoding=\"ISO-8859-1\")\n",
        "answers = pd.read_csv(\"/content/drive/MyDrive/DM/Answers.csv\", encoding=\"ISO-8859-1\")\n",
        "\n",
        "index_outfile = \"/content/drive/MyDrive/DM/index.csv\""
      ],
      "metadata": {
        "id": "okdIHgf7Qy-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RbtMSoV-U_0"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZCHmmjqvb0b"
      },
      "source": [
        "It can be interesting and helpful to analyze:\n",
        "\n",
        "*   the distribution of the scores among the questions,\n",
        "*   number of answers for question (and scores of those answers);\n",
        "*   creation dates for the posts;\n",
        "*   if a post was closed (and why);\n",
        "*   popular users (who answered a lot of questions)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aMmDu1Dpj8q"
      },
      "source": [
        "<h2>Questions</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NupnZcXjyjfN"
      },
      "source": [
        "*   Id: id of the question;\n",
        "*   OwnerUserId: id of the account who post the question;\n",
        "*   CreationDate: when the question was posted;\n",
        "*   ClosedDate: when the question was closed;\n",
        "*   Score: upvotes - downvotes;\n",
        "*   Title: title of the question;\n",
        "*   Body: the question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkAxz68mbUBs"
      },
      "outputs": [],
      "source": [
        "questions = pd.read_csv(\"/content/drive/MyDrive/DM/Questions.csv\",encoding=\"ISO-8859-1\") #utf-8 is not good in this case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEwlkjWtbWKK"
      },
      "outputs": [],
      "source": [
        "questions.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wspAqCIigkdV"
      },
      "outputs": [],
      "source": [
        "questions.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgynb7ZUflJN"
      },
      "outputs": [],
      "source": [
        "#What is the distribution of the scores among the questions?\n",
        "score_distribution = questions[\"Score\"].value_counts(bins=20)\n",
        "score_distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBVv6gSHq1PG"
      },
      "outputs": [],
      "source": [
        "#negative scores\n",
        "negative_scores_questions = questions[questions[\"Score\"] < 0]\n",
        "negative_scores_questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXPO7_PqiAqV"
      },
      "outputs": [],
      "source": [
        "#Posts with a score greater than 4000\n",
        "best_posts = questions[questions[\"Score\"] >4000]\n",
        "best_posts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nRsYk40qI-q"
      },
      "outputs": [],
      "source": [
        "#Count NaN values -> most of them in ClosedDate\n",
        "questions.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dugxDhRlpezf"
      },
      "source": [
        "<h2>Answers</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjCVejxuyFPl"
      },
      "source": [
        "\n",
        "*   Id: id of the answer;\n",
        "*   OwnerUserId: id of the account who post the answer;\n",
        "*   CreationDate: when the answer was posted;\n",
        "*   ParentId: Id of the question;\n",
        "*   Score: upvotes - downvotes;\n",
        "*   Body: the answer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3J2x9cgeFORD"
      },
      "outputs": [],
      "source": [
        "answers = pd.read_csv(\"/content/drive/MyDrive/Data Mining/Project/Answers.csv\",encoding=\"ISO-8859-1\") #utf-8 is not good in this case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHzWWfaNFggg"
      },
      "outputs": [],
      "source": [
        "answers.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfTUfpAEFSSV"
      },
      "outputs": [],
      "source": [
        "answers.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ni0sADlFrMb"
      },
      "outputs": [],
      "source": [
        "#Distribution for the scores of the answers\n",
        "score_distribution = answers[\"Score\"].value_counts(bins=20)\n",
        "score_distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ4-a09Iw0DO"
      },
      "outputs": [],
      "source": [
        "#negative scores\n",
        "negative_scores_answers = answers[answers[\"Score\"] < 0]\n",
        "negative_scores_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBb1Bk8yGM3w"
      },
      "outputs": [],
      "source": [
        "#Number of answers for question\n",
        "answers_for_post = answers.groupby([\"ParentId\"]).count()[\"Id\"]\n",
        "answers_for_post"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DF1p9H25uNQN"
      },
      "outputs": [],
      "source": [
        "#max number of answers for a post\n",
        "answers_for_post.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH9S_AVPuFeQ"
      },
      "outputs": [],
      "source": [
        "#How many questions have a certain number of answers?\n",
        "print(\"#answers   #questions\")\n",
        "answers_for_post.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEiYYRsyrql2"
      },
      "outputs": [],
      "source": [
        "#How many NaN values?\n",
        "answers.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhH_hoaHx4nS"
      },
      "outputs": [],
      "source": [
        "#How many questions were answered by the users?\n",
        "users_and_number_of_answers = answers[\"OwnerUserId\"].value_counts()\n",
        "print(\"UserId     #answers\")\n",
        "users_and_number_of_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UKM1Ol81yHo"
      },
      "outputs": [],
      "source": [
        "#Distribution of the number of answers posted by different users\n",
        "print(\"#answers    #users\")\n",
        "users_and_number_of_answers.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKi7XF15pqBw"
      },
      "source": [
        "<h2>Tags</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gcYNdLe40yH"
      },
      "source": [
        "\n",
        "*   Id: id of the question\n",
        "*   Tag: just the tag :)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M21T5o2w4oJU"
      },
      "outputs": [],
      "source": [
        "tags = pd.read_csv(\"/content/drive/MyDrive/Data Mining/Project/Tags.csv\",encoding=\"ISO-8859-1\") #utf-8 is not good in this case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdfkaejx4oGi"
      },
      "outputs": [],
      "source": [
        "tags.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suT2aso54w2v"
      },
      "outputs": [],
      "source": [
        "#How many rows?\n",
        "tags.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8bgqlxp7FtF"
      },
      "outputs": [],
      "source": [
        "#Check if there are some null values\n",
        "tags.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRmlKKwW5L8W"
      },
      "outputs": [],
      "source": [
        "#Number of tags for post\n",
        "number_of_tags_for_post = tags[\"Id\"].value_counts()\n",
        "print(\"Post     #tags\")\n",
        "number_of_tags_for_post"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGqbH65N70B9"
      },
      "outputs": [],
      "source": [
        "#Distribution of number of tags\n",
        "number_of_tags_for_post.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InKl0Ru19ilk"
      },
      "outputs": [],
      "source": [
        "#Number of tags for post\n",
        "tags_used = tags[\"Tag\"].value_counts()\n",
        "tags_used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJAHeGyPrI3i"
      },
      "outputs": [],
      "source": [
        "counter = 0\n",
        "for i in tags_used:\n",
        "  if i > 10:\n",
        "    counter+=1\n",
        "counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0pGmlDf-QvZ"
      },
      "outputs": [],
      "source": [
        "#How many tags appear a certain number of times\n",
        "print(\"#occurrences #tags\")\n",
        "occ_tags = tags_used.value_counts()\n",
        "occ_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTMq1mah8-nC"
      },
      "outputs": [],
      "source": [
        "#distribution of how many tags appear a certain number of times\n",
        "tags_used_groups = tags_used.value_counts(bins=20)\n",
        "tags_used_groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxw8aRjTWf9w"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAinZNvHGmmo"
      },
      "source": [
        "*As* shown in the next cell, the body of the questions have a lot of things that I have to elaborate in the preprocessing phase: HTML tags, punctuation, stop words, URLs and programming code. Right now I think I will remove HTML tags, punctuation and stop words. Programming code can be handled by CodeBERT, so I will leave it there. Still unsure what to do with URLs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2UUCjgl4ndC"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup as soup\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQn-C3y14OcC"
      },
      "outputs": [],
      "source": [
        "def cleanpunc(sentence): \n",
        "    no_punct = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "    return  no_punct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcP2XtWi4l1a"
      },
      "outputs": [],
      "source": [
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    phrase = re.sub(r\"\\n\", \" \", phrase)\n",
        "    return phrase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YMCznUT5PTR"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "print ('list of stop words:', stop_words)\n",
        "\n",
        "def clean_stop_words(total_text):\n",
        "    if type(total_text) is not int:\n",
        "        string = \"\"\n",
        "        for word in total_text.split():\n",
        "            if not word in stop_words:\n",
        "                string += word + \" \"\n",
        "        return string  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgb-nStZFVoy"
      },
      "outputs": [],
      "source": [
        "def preprocessing_operations(text):\n",
        "  splitted_text_code = re.split('<pre><code>|</code></pre>', text)\n",
        "  res = []\n",
        "  for idx, text in enumerate(splitted_text_code):\n",
        "    if idx%2 == 0:\n",
        "      no_html = soup(text, \"lxml\").text\n",
        "      no_punctuation = cleanpunc(no_html)\n",
        "      no_contractions = decontracted(no_punctuation)\n",
        "      no_stopwords = clean_stop_words(no_contractions)\n",
        "      res.append(no_stopwords)\n",
        "    else:\n",
        "      res.append(text)\n",
        "  return res\n",
        "\n",
        "def preprocess_data(data):\n",
        "  cleaned_text = []\n",
        "  if type(data)==type(\"string\"):\n",
        "    cleaned_text = preprocessing_operations(data)\n",
        "  else:\n",
        "    body = data[\"Body\"]\n",
        "    for q in body:\n",
        "      cleaned_text.append(preprocessing_operations(q))\n",
        "  return cleaned_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wus1mVOuh710"
      },
      "source": [
        "# Jina"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T95C16q5jmWT"
      },
      "outputs": [],
      "source": [
        "!pip install jina"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52I4frUGu5_Q"
      },
      "outputs": [],
      "source": [
        "! pip install \"transformers\" \"pytorch-lightning\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCtiGYEq7V1B"
      },
      "outputs": [],
      "source": [
        "!apt install libomp-dev\n",
        "!pip install faiss\n",
        "!pip install --upgrade faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bif-D0NqnPx"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from __future__ import division\n",
        "from math import ceil\n",
        "import numpy as np\n",
        "from jina import Flow, Executor, requests, Document, DocumentArray, DocumentArrayMemmap\n",
        "import faiss\n",
        "import time\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frEE5DlmB6d1"
      },
      "outputs": [],
      "source": [
        "device = 0\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piUtOfu_f5rH"
      },
      "source": [
        "The authors of CodeBert set the MAX_LENGTH for the sentences to 512(+2) so, if the input vector is too big, I can not compute the embeddings -> two possible solutions (https://github.com/microsoft/CodeBERT/issues/16):\n",
        "\n",
        "*   use an RNN over k representations to obtain a final embedding;\n",
        "*   take the average of the representations (https://towardsdatascience.com/how-to-do-average-and-max-word-embedding-for-long-sentences-f3531e99d998)\n",
        "\n",
        "To use the cosine distance we need vectors that have same length ->there are two ways to obtain a representation for the texts of the same length:\n",
        "\n",
        "*   use the [CLS] token;\n",
        "*   use the average of the vectors\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2TY3cvPj9FC"
      },
      "outputs": [],
      "source": [
        "class MyTransformer(Executor):\n",
        "    \"\"\"Transformer executor class \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            pretrained_model_name_or_path: str = \"microsoft/codebert-base\",\n",
        "            *args,\n",
        "            device: str = 'cpu',\n",
        "            **kwargs,\n",
        "    ):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path)\n",
        "        self.model = AutoModel.from_pretrained(pretrained_model_name_or_path)\n",
        "        self.model.to(device)\n",
        "        print(\"Device used: {}\".format(self.model.device))\n",
        "\n",
        "    def compute_embedding(self,tokens_ids):\n",
        "      if(len(tokens_ids) < 512):  \n",
        "        context_embeddings = self.model(torch.tensor(tokens_ids)[None,:].to(device))[0]\n",
        "      else:\n",
        "        k = ceil(len(tokens_ids) / 512.0)\n",
        "        chunks = np.array_split(tokens_ids, k)\n",
        "        chunks_tensor = torch.tensor(chunks[0])[None,:].to(device)\n",
        "        context_embeddings_list = self.model(chunks_tensor)[0].to(device)\n",
        "        for i in range(1, len(chunks)):\n",
        "          chunks_tensor = torch.tensor(chunks[i])[None,:].to(device)\n",
        "          context_embeddings_list = torch.cat((context_embeddings_list, self.model(chunks_tensor)[0]), 1)\n",
        "        dim = context_embeddings_list.shape[-1]\n",
        "        context_embeddings = context_embeddings_list.to(device)\n",
        "      #compute the average of the vectors\n",
        "      avg_embeddings = torch.mean(context_embeddings,1)[0]\n",
        "      return avg_embeddings\n",
        "\n",
        "    @requests\n",
        "    def encode(self, docs: 'DocumentArray', *args, **kwargs):\n",
        "        start = time.time()\n",
        "        tokens = [self.tokenizer.cls_token]\n",
        "        texts = docs.get_attributes(\"text\")\n",
        "        for idx, q in enumerate(texts): \n",
        "          cleaned_q = preprocess_data(q)\n",
        "          tokens = [self.tokenizer.cls_token]\n",
        "          for l in cleaned_q:\n",
        "            code_tokens = self.tokenizer.tokenize(l)\n",
        "            tokens += code_tokens\n",
        "            tokens += [self.tokenizer.sep_token]\n",
        "          tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "          docs[idx].embedding = self.compute_embedding(tokens_ids)\n",
        "        print(\"Time needed to encode {} documents: {}\".format(len(docs), time.time()-start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQMAhi2rnYnF"
      },
      "outputs": [],
      "source": [
        "class MyIndexer(Executor): #Indexer with Faiss library\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        #self._docs = DocumentArrayMemmap() \n",
        "        self.index_output = None\n",
        "        self.index_file = None\n",
        "        for key, value in kwargs.items():\n",
        "          if (key == \"index_output\"):\n",
        "            self.index_output = value\n",
        "          elif(key == \"index_file\"):\n",
        "            self.index_file == value\n",
        "    \n",
        "    def load_index(self, **kwargs):\n",
        "      self.my_index = faiss.read_index(self.index_file)\n",
        "\n",
        "    @requests(on='/index')\n",
        "    def index(self, docs: DocumentArray, operation: str = None, **kwargs): \n",
        "      dim = docs.embeddings.shape[1]\n",
        "      nlist = 50  # how many cells\n",
        "      m = 8  # number of centroid IDs in final compressed vectors\n",
        "      bits = 8 # number of bits in each centroid\n",
        "\n",
        "      embeddings = docs.embeddings.cpu().detach().numpy()\n",
        "      quantizer = faiss.IndexFlatL2(dim)\n",
        "      self.my_index = faiss.IndexIVFFlat(quantizer, dim, nlist)\n",
        "\n",
        "      start = time.time()\n",
        "      self.my_index.train(embeddings)\n",
        "      self.my_index.add(embeddings)\n",
        "      print(\"Time needed to train and add {} texts to the index: {} s\".format(self.my_index.ntotal, time.time()-start))\n",
        "\n",
        "      if(operation == \"w\"):\n",
        "        #write index on disk\n",
        "        faiss.write_index(self.my_index, self.index_output)\n",
        "\n",
        "    # def print_matches(self, docs): #write it again\n",
        "    #   for d in docs:\n",
        "    #     print(\"Query Id: {}\".format(d.id))\n",
        "    #     for i, r in enumerate(d.matches):\n",
        "    #       print(\"{}th result-> id: {} with cosine value: {}\".format(i+1, r.id, r.scores['cosine'].value))\n",
        "\n",
        "    @requests(on='/search')\n",
        "    def search(self, docs: DocumentArray, k:int = 4, **kwargs):\n",
        "        s, d = self.my_index.search(docs.embeddings.numpy(), k)\n",
        "        start = time.time()\n",
        "        print(\"Time needed to search {} query: {} s\".format(len(docs), time.time()-start))\n",
        "        print(\"Indexes of the most similar documents: {}\\nwith distance: {}\".format(d,s))\n",
        "        return d[0]\n",
        "          \n",
        "    def print_index(self):\n",
        "      for d in self.index:\n",
        "        print(\"Document id: {}\\nembedding: {} of shape: {}\".format(d.id, d.embedding, d.embedding.shape))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getKey(item):\n",
        "  return item[2]\n",
        "\n",
        "def get_answers(docIds: list, questions, answers):\n",
        "  for i, idx in enumerate(docIds):\n",
        "    print(\"{}th result:\".format(i+1))\n",
        "    #document\n",
        "    doc = questions.loc[idx]\n",
        "    doc_id = doc.Id\n",
        "    #question's title\n",
        "    title = doc[\"Title\"]\n",
        "    #question's body\n",
        "    body_q = doc[\"Body\"]\n",
        "    #answers\n",
        "    answers_q = answers.loc[answers.ParentId == doc_id]\n",
        "    answers.drop(answers[answers.Score <= 0].index, inplace=True)\n",
        "    if (answers_q.empty):\n",
        "      #skip this question on SO -> maybe add as feature the fact that other documents will be retrieved instead\n",
        "      continue\n",
        "    answers_texts = []\n",
        "    for a in answers_q.itertuples():\n",
        "      answers_texts.append((a.Id, a.Body, a.Score))\n",
        "    answers_texts_sorted = sorted(answers_texts, key=getKey, reverse=True)\n",
        "    print(\"Doc Id: {}\\nTitle: {}\\nText:\\n{}\".format(doc_id, title, body_q))\n",
        "    for j, a in enumerate(answers_texts_sorted):\n",
        "      print(\"----------------------------\")\n",
        "      print(\"{}th answer's Id: {}, with score: {} and text:\\n{}\".format(j+1, a[0], a[2], a[1]))\n",
        "    print(\"########################################\")"
      ],
      "metadata": {
        "id": "LHJ-SxjCOGxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_with_gpu(num_docs: int = 100, query:str = None, **kwargs):\n",
        "  start = time.time()\n",
        "  #index\n",
        "  i = MyIndexer(index_output = kwargs[\"index_output\"], index_file = kwargs[\"index_file\"]) #pass operation = 'w' to write and save a new index on disk\n",
        "  if (num_docs >= 0):\n",
        "    #documents in the new index\n",
        "    if(num_docs == 0): #load the whole dataset\n",
        "      docArray = DocumentArray([Document(id=questions.iloc[i].Id, text=questions.iloc[i].Body) for i in range(len(questions))])\n",
        "      print(\"Time needed to read the whole dataset: {} s\".format(time.time()-start))\n",
        "    else:\n",
        "      docArray = DocumentArray([Document(id=questions.iloc[i].Id, text=questions.iloc[i].Body) for i in range(num_docs)])\n",
        "      print(\"Time needed to read {} texts: {} s\".format(num_docs, time.time()-start))\n",
        "    #embeddings\n",
        "    e = MyTransformer(device=device)\n",
        "    e.encode(docArray)\n",
        "    #create new index\n",
        "    i.index(docArray) \n",
        "  else: #load index from disk\n",
        "    i.load_index(index_outfile)\n",
        "  #query\n",
        "  if(query is None):\n",
        "    q = DocumentArray([Document(text=questions.iloc[0].Body)])\n",
        "    e.encode(q)\n",
        "  else:\n",
        "    q = DocumentArray([Document(text = query)])\n",
        "    e.encode(q)\n",
        "  #search\n",
        "  docs = i.search(q, k=5)\n",
        "  get_answers(docs, questions, answers)"
      ],
      "metadata": {
        "id": "ebleHJcnBTN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRws9l2ZkObO"
      },
      "outputs": [],
      "source": [
        "flow = (\n",
        "        Flow()\n",
        "            .add(name='MyTransformer', uses=MyTransformer, uses_with={'device': \"cuda:0\"}, gpus='all')\n",
        "            .add(name='MyIndexer', uses=MyIndexer)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4l1alya2TxK"
      },
      "outputs": [],
      "source": [
        "flow.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCgdQx04h-Zp"
      },
      "outputs": [],
      "source": [
        "query_encoder = MyTransformer(device=device)\n",
        "num_docs = 100000 #number of documents to read, 0 to load the whole dataset, -1 to load the index from the disk\n",
        "\n",
        "if(device!=\"cpu\"): #if you are using GPU\n",
        "  print(\"\\nInsert your query ('n' to not pass a query): \")\n",
        "  q = input()\n",
        "  if(q=='n'): #use the first question as query\n",
        "    test_with_gpu(num_docs, index_output = index_outfile, index_file = index_outfile)\n",
        "  else:\n",
        "    test_with_gpu(num_docs, q, index_output = index_outfile, index_file = index_outfile)\n",
        "else: #if you are not using GPU\n",
        "  with flow as f:\n",
        "      docArray = DocumentArray([Document(id=questions.iloc[i].Id, text=questions.iloc[i].Body) for i in range(num_docs)])\n",
        "      f.index(docArray, index_output = index_outfile, index_file = index_outfile)\n",
        "      while(True):\n",
        "        print(\"\\nInsert your query (q to quit): \")\n",
        "        q = input()\n",
        "        if (q == \"q\"):\n",
        "          print(\"\\n\\nGoodbye!\")\n",
        "          break\n",
        "        query_encoder.encode(DocumentArray([q]))\n",
        "        d = f.search(\n",
        "            inputs=DocumentArray(q)\n",
        "            )\n",
        "        get_answers(d, questions, answers)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "0RbtMSoV-U_0",
        "rxw8aRjTWf9w"
      ],
      "name": "DM_project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}